{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "804bd01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.7496080456508416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>true_stars</th>\n",
       "      <th>predicted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flying Elephants at PDX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.112953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Reclaimory</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.698058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Clips</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.254470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crossfit Terminus</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.496943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob Likes Thai Food</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.796281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             business_name  true_stars  predicted_stars\n",
       "0  Flying Elephants at PDX         4.0         4.112953\n",
       "1           The Reclaimory         3.5         3.698058\n",
       "2              Great Clips         4.0         3.254470\n",
       "3        Crossfit Terminus         3.0         2.496943\n",
       "4      Bob Likes Thai Food         4.5         2.796281"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "helpers = SourceFileLoader(\"helpers\", \"./helpers.py\").load_module()\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "business_data_frame = pd.read_json('./dataset/business.json', lines=True)\n",
    "\n",
    "# Removing all businesses with less then 20 reviews because of project requirements\n",
    "filtered_business_data_frame = business_data_frame[business_data_frame['review_count'] >= 20]\n",
    "\n",
    "review_data_frame = pd.read_json('./dataset/reviews.json', lines=True, nrows=5000)\n",
    "\n",
    "# having all reviews joined together with the business id so all the text can be in one row. \n",
    "# this will help when we vectorize the text\n",
    "aggregated_business_reviews = review_data_frame.groupby('business_id')['text'].sum()\n",
    "\n",
    "aggregated_business_review_data_frame = pd.DataFrame({'business_id': aggregated_business_reviews.index, 'all_reviews': aggregated_business_reviews.values})\n",
    "\n",
    "# join the tables so that we can have the business and reviews in the same table. \n",
    "# this will help us later when we want to refer to business attributes\n",
    "joined_business_review_data_frame = pd.merge(business_data_frame, aggregated_business_review_data_frame, on='business_id')\n",
    "\n",
    "# Compute a weight to each word which signifies the importance of the word\n",
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english', max_features = 500, min_df=1)\n",
    "\n",
    "reviewMatrix = vectorizer.fit_transform(joined_business_review_data_frame['all_reviews'])\n",
    "\n",
    "# Convert both the reviews and the stars to numpy arrays so the data matches when we go to test\n",
    "numpyReviews = reviewMatrix.toarray()\n",
    "numpyStars = joined_business_review_data_frame['stars'].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(numpyReviews, numpyStars, test_size=0.20, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# having any more layers did not help\n",
    "# 5 for this layer seem to be the sweet spot. any lower increased RMSE. any Higher had the same value until I went past 10\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# sgd ended up performing the best. I found that lowering the learning_rate had little to no effect. It just increased\n",
    "# the amount of time to fit\n",
    "sgd = optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "# stops when data is flattening out\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "model.fit(x_train,y_train, validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "df_business_name = pd.DataFrame(joined_business_review_data_frame['name'].to_numpy(), columns=['business_name'])\n",
    "df_y = pd.DataFrame(y_test, columns=['true_stars'])\n",
    "df_pred = pd.DataFrame(pred, columns=['predicted_stars'])\n",
    "result = pd.concat([df_business_name, df_y, df_pred],axis=1)\n",
    "\n",
    "result[0:5]\n",
    "# print(result)\n",
    "\n",
    "# helpers.chart_regression(pred.flatten(),y_test, sort=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc41a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ef77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e6d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c2c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7db50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d96e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ecfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907cc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
