{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6163c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "helpers = SourceFileLoader(\"helpers\", \"../helpers.py\").load_module()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "network_intrusion_data_frame = pd.read_csv('./dataset/network_intrusion_data.csv')\n",
    "\n",
    "\n",
    "def label_encoder(label):\n",
    "    if(label == 'normal.'):\n",
    "        return '0'\n",
    "    return '1'\n",
    "\n",
    "\n",
    "columns = [\n",
    "    'duration',   \n",
    "    'protocol_type',    \n",
    "    'service',    \n",
    "    'flag',    \n",
    "    'src_bytes',    \n",
    "    'dst_bytes',    \n",
    "    'land',    \n",
    "    'wrong_fragment',    \n",
    "    'urgent',    \n",
    "    'hot',    \n",
    "    'num_failed_logins',    \n",
    "    'logged_in',    \n",
    "    'num_compromised',    \n",
    "    'root_shell',    \n",
    "    'su_attempted',\n",
    "    'num_root',    \n",
    "    'num_file_creations',    \n",
    "    'num_shells',    \n",
    "    'num_access_files',    \n",
    "    'num_outbound_cmds',    \n",
    "    'is_host_login',   \n",
    "    'is_guest_login',   \n",
    "    'count',  \n",
    "    'srv_count',  \n",
    "    'serror_rate',   \n",
    "    'srv_serror_rate', \n",
    "    'rerror_rate',  \n",
    "    'srv_rerror_rate', \n",
    "    'same_srv_rate',   \n",
    "    'diff_srv_rate',    \n",
    "    'srv_diff_host_rate',  \n",
    "    'dst_host_count', \n",
    "    'dst_host_srv_count',  \n",
    "    'dst_host_same_srv_rate', \n",
    "    'dst_host_diff_srv_rate',    \n",
    "    'dst_host_same_src_port_rate',  \n",
    "    'dst_host_srv_diff_host_rate',  \n",
    "    'dst_host_serror_rate',  \n",
    "    'dst_host_srv_serror_rate',  \n",
    "    'dst_host_rerror_rate',   \n",
    "    'dst_host_srv_rerror_rate',    \n",
    "    'outcome'] \n",
    "\n",
    "\n",
    "network_intrusion_data_frame.columns = columns\n",
    "\n",
    "\n",
    "\n",
    "# drop rows with missing values since data is not complete\n",
    "network_intrusion_data_frame.dropna()\n",
    "\n",
    "# drop redudant rows so we do not get biased data in testing phase\n",
    "network_intrusion_data_frame.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# here i encoded all normal outcomes to 0 and attacks to 1\n",
    "network_intrusion_data_frame['outcome'] = network_intrusion_data_frame['outcome'].map(label_encoder)\n",
    "\n",
    "stringColumnsToEncode = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "outcome = helpers.encode_text_index(network_intrusion_data_frame,'outcome')\n",
    "\n",
    "for x in columns:\n",
    "    if(x != 'outcome'):\n",
    "        helpers.encode_text_index(network_intrusion_data_frame, x)\n",
    "    \n",
    "x,y = helpers.to_xy(network_intrusion_data_frame, 'outcome')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b637800",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Network Training \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7985797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 109188 samples, validate on 36397 samples\n",
      "Epoch 1/100\n",
      "109188/109188 - 4s - loss: 0.4189 - val_loss: 0.1009\n",
      "Epoch 2/100\n",
      "109188/109188 - 4s - loss: 0.1057 - val_loss: 0.0828\n",
      "Epoch 3/100\n",
      "109188/109188 - 4s - loss: 0.0734 - val_loss: 0.0666\n",
      "Epoch 4/100\n",
      "109188/109188 - 4s - loss: 0.0576 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "109188/109188 - 3s - loss: 0.0318 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "109188/109188 - 4s - loss: 0.0225 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "109188/109188 - 4s - loss: 0.0168 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "109188/109188 - 4s - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 9/100\n",
      "109188/109188 - 4s - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 10/100\n",
      "109188/109188 - 4s - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 11/100\n",
      "109188/109188 - 4s - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 12/100\n",
      "109188/109188 - 4s - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 13/100\n",
      "109188/109188 - 4s - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 14/100\n",
      "109188/109188 - 4s - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 15/100\n",
      "109188/109188 - 4s - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 00015: early stopping\n",
      "1\n",
      "Train on 109188 samples, validate on 36397 samples\n",
      "Epoch 1/100\n",
      "109188/109188 - 4s - loss: 2.2041 - val_loss: 0.0648\n",
      "Epoch 2/100\n",
      "109188/109188 - 4s - loss: 0.1233 - val_loss: 0.0965\n",
      "Epoch 3/100\n",
      "109188/109188 - 4s - loss: 0.1109 - val_loss: 0.0639\n",
      "Epoch 4/100\n",
      "109188/109188 - 4s - loss: 0.0705 - val_loss: 0.0803\n",
      "Epoch 5/100\n",
      "109188/109188 - 4s - loss: 0.0529 - val_loss: 0.0310\n",
      "Epoch 6/100\n",
      "109188/109188 - 4s - loss: 0.0338 - val_loss: 0.0293\n",
      "Epoch 7/100\n",
      "109188/109188 - 4s - loss: 0.0216 - val_loss: 0.0726\n",
      "Epoch 8/100\n",
      "109188/109188 - 4s - loss: 0.0223 - val_loss: 0.0146\n",
      "Epoch 9/100\n",
      "109188/109188 - 4s - loss: 0.0182 - val_loss: 0.0155\n",
      "Epoch 10/100\n",
      "109188/109188 - 3s - loss: 0.0173 - val_loss: 0.0471\n",
      "Epoch 11/100\n",
      "109188/109188 - 4s - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "109188/109188 - 4s - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 13/100\n",
      "109188/109188 - 4s - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "109188/109188 - 4s - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "109188/109188 - 4s - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "109188/109188 - 4s - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 17/100\n",
      "109188/109188 - 4s - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 18/100\n",
      "109188/109188 - 4s - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "109188/109188 - 4s - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "109188/109188 - 4s - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 21/100\n",
      "109188/109188 - 4s - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 22/100\n",
      "109188/109188 - 4s - loss: 0.0083 - val_loss: 0.0094\n",
      "Epoch 23/100\n",
      "109188/109188 - 4s - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 24/100\n",
      "109188/109188 - 4s - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "109188/109188 - 4s - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 26/100\n",
      "109188/109188 - 4s - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 00026: early stopping\n",
      "2\n",
      "Train on 109188 samples, validate on 36397 samples\n",
      "Epoch 1/100\n",
      "109188/109188 - 4s - loss: 0.3253 - val_loss: 0.1254\n",
      "Epoch 2/100\n",
      "109188/109188 - 3s - loss: 0.0907 - val_loss: 0.0375\n",
      "Epoch 3/100\n",
      "109188/109188 - 3s - loss: 0.0543 - val_loss: 0.0214\n",
      "Epoch 4/100\n",
      "109188/109188 - 4s - loss: 0.0473 - val_loss: 0.0518\n",
      "Epoch 5/100\n",
      "109188/109188 - 4s - loss: 0.0366 - val_loss: 0.0149\n",
      "Epoch 6/100\n",
      "109188/109188 - 4s - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 7/100\n",
      "109188/109188 - 3s - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "109188/109188 - 4s - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "109188/109188 - 4s - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "109188/109188 - 4s - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 11/100\n",
      "109188/109188 - 3s - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 12/100\n",
      "109188/109188 - 3s - loss: 0.0087 - val_loss: 0.0105\n",
      "Epoch 13/100\n",
      "109188/109188 - 3s - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 14/100\n",
      "109188/109188 - 3s - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 15/100\n",
      "109188/109188 - 3s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "109188/109188 - 3s - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 17/100\n",
      "109188/109188 - 4s - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 18/100\n",
      "109188/109188 - 3s - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 00018: early stopping\n",
      "3\n",
      "Train on 109188 samples, validate on 36397 samples\n",
      "Epoch 1/100\n",
      "109188/109188 - 4s - loss: 0.6553 - val_loss: 0.0771\n",
      "Epoch 2/100\n",
      "109188/109188 - 4s - loss: 0.1122 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "109188/109188 - 4s - loss: 0.0720 - val_loss: 0.0311\n",
      "Epoch 4/100\n",
      "109188/109188 - 4s - loss: 0.0470 - val_loss: 0.0138\n",
      "Epoch 5/100\n",
      "109188/109188 - 4s - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 6/100\n",
      "109188/109188 - 3s - loss: 0.0215 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "109188/109188 - 4s - loss: 0.0165 - val_loss: 0.0101\n",
      "Epoch 8/100\n",
      "109188/109188 - 4s - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 9/100\n",
      "109188/109188 - 4s - loss: 0.0109 - val_loss: 0.0148\n",
      "Epoch 10/100\n",
      "109188/109188 - 4s - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 11/100\n",
      "109188/109188 - 4s - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 12/100\n",
      "109188/109188 - 4s - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 13/100\n",
      "109188/109188 - 4s - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 14/100\n",
      "109188/109188 - 3s - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 15/100\n",
      "109188/109188 - 3s - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 16/100\n",
      "109188/109188 - 4s - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 17/100\n",
      "109188/109188 - 4s - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 18/100\n",
      "109188/109188 - 4s - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 19/100\n",
      "109188/109188 - 4s - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 20/100\n",
      "109188/109188 - 4s - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 00020: early stopping\n",
      "4\n",
      "Train on 109188 samples, validate on 36397 samples\n",
      "Epoch 1/100\n",
      "109188/109188 - 4s - loss: 0.6000 - val_loss: 0.0810\n",
      "Epoch 2/100\n",
      "109188/109188 - 4s - loss: 0.0680 - val_loss: 0.0458\n",
      "Epoch 3/100\n",
      "109188/109188 - 4s - loss: 0.0381 - val_loss: 0.0288\n",
      "Epoch 4/100\n",
      "109188/109188 - 4s - loss: 0.0282 - val_loss: 0.0188\n",
      "Epoch 5/100\n",
      "109188/109188 - 4s - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "109188/109188 - 4s - loss: 0.0180 - val_loss: 0.0154\n",
      "Epoch 7/100\n",
      "109188/109188 - 6s - loss: 0.0169 - val_loss: 0.0138\n",
      "Epoch 8/100\n",
      "109188/109188 - 4s - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "109188/109188 - 6s - loss: 0.0113 - val_loss: 0.0206\n",
      "Epoch 10/100\n",
      "109188/109188 - 6s - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "109188/109188 - 4s - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 12/100\n",
      "109188/109188 - 4s - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 13/100\n",
      "109188/109188 - 4s - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "109188/109188 - 4s - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 15/100\n",
      "109188/109188 - 4s - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 16/100\n",
      "109188/109188 - 4s - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 17/100\n",
      "109188/109188 - 4s - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 18/100\n",
      "109188/109188 - 4s - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 19/100\n",
      "109188/109188 - 4s - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "     # Build network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6da5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.9982141385279006\n",
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     21885\n",
      "           1       1.00      1.00      1.00     14512\n",
      "\n",
      "    accuracy                           1.00     36397\n",
      "   macro avg       1.00      1.00      1.00     36397\n",
      "weighted avg       1.00      1.00      1.00     36397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Final accuracy: {}\".format(score))\n",
    "    \n",
    "\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "helpers.plot_confusion_matrix(cm, outcome)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9c414",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b06997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145585, 42)\n",
      "(145585, 1)\n"
     ]
    }
   ],
   "source": [
    "# turning into numpy array simulates an image\n",
    "x = network_intrusion_data_frame.to_numpy().astype(\"float32\")\n",
    "y = np.random.randint(2, size=(len(x), 1))\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13c67219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145585, 1, 42, 1)\n",
      "(145585, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "rowLength = len(x)\n",
    "columLength = len(x[0])\n",
    "\n",
    "x = x.reshape((rowLength, 1, columLength, 1))\n",
    "y_one_hot = tf.keras.utils.to_categorical(y, 2)\n",
    "\n",
    "print(x.shape)\n",
    "print(y_one_hot.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395886b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f2b53e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (109188, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0a18aa4b8c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (109188, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# model = Sequential()\n",
    "\n",
    "# cnn = Sequential()\n",
    "# cnn.add(Conv2D(64, kernel_size=(1, 2), strides=(1, 1),\n",
    "#                  activation='relu'))\n",
    "\n",
    "# cnn.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "# cnn.fit(x_train, y_train,\n",
    "#           epochs=10,\n",
    "#           verbose=2,\n",
    "#           validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "# print('done')\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(64, kernel_size=(1, 2), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(1, 42, 1)))\n",
    "\n",
    "# the above code is equivalent to \n",
    "# model.add(Conv1D(64, kernel_size=3, strides=1, activation='relu', input_shape=(128, 1)))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
    "\n",
    "cnn.add(Conv2D(128, kernel_size=(1, 2), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
    "    \n",
    "    \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1024, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "cnn.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75b468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
